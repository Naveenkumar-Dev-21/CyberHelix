#!/usr/bin/env python3
"""
Automated Penetration Testing System Launcher
Complete agentic AI-powered penetration testing orchestrator
"""

import os
import sys
import asyncio
import argparse
from pathlib import Path

# Add src to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def banner():
    """Display system banner"""
    print("""
╔═══════════════════════════════════════════════════════════╗
║              AUTOMATED PENETRATION TESTING                ║
║                    ORCHESTRATOR v1.0                     ║
║                                                           ║
║  🤖 AI-Powered • 🔧 Multi-Platform • 🚀 Autonomous        ║
║  🛡️  Network • 🌐 Web • 📱 Mobile • ☁️  Cloud • 📡 IoT    ║
╚═══════════════════════════════════════════════════════════╝
""")

async def run_agentic_assessment(targets, assessment_type="comprehensive"):
    """Run complete agentic AI assessment"""
    
    print(f"\n🚀 Starting Agentic AI Penetration Testing...")
    print(f"📋 Assessment Type: {assessment_type}")
    print(f"🎯 Targets: {len(targets)}")
    
    try:
        # Import the agentic AI system
        from src.agentic_ai import AgenticPentestAI
        
        # Initialize the AI agent
        print("\n🤖 Initializing AI Agent...")
        agent = AgenticPentestAI()
        
        results = []
        
        for i, target in enumerate(targets, 1):
            print(f"\n{'='*60}")
            print(f"🎯 ANALYZING TARGET {i}/{len(targets)}: {target}")
            print('='*60)
            
            # Generate intelligent request based on target
            if target.startswith(('http://', 'https://')):
                request = f"Perform comprehensive web application security assessment of {target}"
            elif target.endswith(('.apk', '.ipa')):
                request = f"Conduct mobile application security analysis of {target}"
            elif '/' in target:  # Network range
                request = f"Execute network penetration testing on {target}"
            else:
                request = f"Perform automated security assessment of {target}"
            
            # Process with agentic AI
            result = agent.process_request(request)
            results.append({
                'target': target,
                'result': result
            })
            
            # Display results
            print(f"\n📊 Assessment Results for {target}:")
            print(f"   ✅ Success Rate: {result.get('success_rate', 0):.1%}")
            print(f"   🔄 AI Iterations: {result.get('iterations', 0)}")
            print(f"   🧠 Knowledge Gained: {len(result.get('knowledge_gained', []))} items")
            print(f"   🔧 Adaptations: {len(result.get('adaptations', []))}")
            print(f"   ⏱️  Processing Time: {result.get('total_time', 0):.2f}s")
        
        # Final summary
        print(f"\n{'='*60}")
        print(f"🎉 AGENTIC AI ASSESSMENT COMPLETE!")
        print('='*60)
        
        total_knowledge = sum(len(r['result'].get('knowledge_gained', [])) for r in results)
        avg_success = sum(r['result'].get('success_rate', 0) for r in results) / len(results)
        total_time = sum(r['result'].get('total_time', 0) for r in results)
        
        print(f"📈 Overall Statistics:")
        print(f"   🎯 Targets Processed: {len(targets)}")
        print(f"   🚀 Average Success Rate: {avg_success:.1%}")
        print(f"   🧠 Total Knowledge Items: {total_knowledge}")
        print(f"   ⏱️  Total Processing Time: {total_time:.2f}s")
        
        # Agent status
        status = agent.get_status()
        print(f"\n🤖 AI Agent Final Status:")
        print(f"   📚 Total Experiences: {status.get('memory_size', 0)}")
        print(f"   ✅ Success Strategies: {status.get('success_strategies', 0)}")
        print(f"   📈 Learning Patterns: {status.get('learned_patterns', 0)}")
        
        return results
        
    except Exception as e:
        print(f"❌ Agentic assessment failed: {e}")
        return None

def run_specialized_assessment(target, platform="auto"):
    """Run platform-specific assessment"""
    
    print(f"\n🔧 Running Specialized Assessment")
    print(f"🎯 Target: {target}")
    print(f"🏷️  Platform: {platform}")
    
    try:
        if platform == "network" or (platform == "auto" and any(c.isdigit() for c in target)):
            from src.network_assessor import NetworkAssessor
            assessor = NetworkAssessor()
            print("🌐 Using Network Assessor")
            
        elif platform == "web" or (platform == "auto" and target.startswith(('http://', 'https://'))):
            from src.web_assessor import WebAssessor  
            assessor = WebAssessor()
            print("🌍 Using Web Application Assessor")
            
        elif platform == "mobile" or (platform == "auto" and target.endswith(('.apk', '.ipa'))):
            from src.mobile_assessor import MobileAssessor
            assessor = MobileAssessor()
            print("📱 Using Mobile Application Assessor")
            
        elif platform == "wireless":
            from src.wireless_assessor import WirelessAssessor
            assessor = WirelessAssessor()
            print("📡 Using Wireless Security Assessor")
            
        elif platform == "cloud":
            from src.cloud_assessor import CloudAssessor
            assessor = CloudAssessor()
            print("☁️ Using Cloud Security Assessor")
            
        elif platform == "iot":
            from src.iot_assessor import IoTAssessor
            assessor = IoTAssessor()
            print("🔌 Using IoT Security Assessor")
            
        else:
            print("🔧 Using Generic Network Assessor")
            from src.network_assessor import NetworkAssessor
            assessor = NetworkAssessor()
        
        print(f"✅ {assessor.__class__.__name__} initialized successfully")
        print(f"🚀 Assessment framework ready for {target}")
        
        return True
        
    except Exception as e:
        print(f"❌ Specialized assessment failed: {e}")
        return False

def run_ai_analysis(targets):
    """Run AI-driven analysis without full execution"""
    
    print(f"\n🧠 Running AI Analysis Only")
    print(f"🎯 Analyzing {len(targets)} targets")
    
    try:
        # Import NLP processor for intelligent analysis
        from src.enhanced_nlp_processor import EnhancedNLPProcessor
        
        nlp = EnhancedNLPProcessor()
        
        for i, target in enumerate(targets, 1):
            print(f"\n📊 Target {i}: {target}")
            
            # Generate assessment request
            request = f"analyze security of {target}"
            intent = nlp.process_request(request)
            
            print(f"   🎯 Identified Intent: {intent.primary_command.value}")
            print(f"   🎪 Confidence: {intent.confidence:.2%}")
            print(f"   🏷️  Target Type: {', '.join(intent.targets) if intent.targets else 'Generic'}")
            print(f"   🔧 Modifiers: {', '.join(intent.modifiers) if intent.modifiers else 'None'}")
            
            # Generate execution plan
            from src.enhanced_nlp_processor import create_enhanced_execution_plan
            plan = create_enhanced_execution_plan(request)
            
            print(f"   📋 Execution Plan: {len(plan['plan'])} steps")
            for j, step in enumerate(plan['plan'][:3], 1):  # Show first 3 steps
                print(f"      {j}. {step['module']} {' '.join(step['args'])}")
            
            if len(plan['plan']) > 3:
                print(f"      ... and {len(plan['plan']) - 3} more steps")
        
        print(f"\n✅ AI Analysis Complete!")
        return True
        
    except Exception as e:
        print(f"❌ AI analysis failed: {e}")
        return False

def demo_mode():
    """Run comprehensive demo of the system"""
    
    print(f"\n🎪 DEMONSTRATION MODE")
    print("="*50)
    
    # Demo targets
    demo_targets = [
        "https://example.com",
        "192.168.1.100", 
        "vulnerable-app.apk",
        "10.0.0.0/24"
    ]
    
    print(f"🎯 Demo targets:")
    for i, target in enumerate(demo_targets, 1):
        print(f"   {i}. {target}")
    
    # Test different components
    print(f"\n🔧 Testing System Components:")
    
    # 1. AI Analysis
    print(f"\n1️⃣ AI-Driven Analysis:")
    run_ai_analysis(demo_targets[:2])
    
    # 2. Specialized Assessment  
    print(f"\n2️⃣ Platform-Specific Assessment:")
    run_specialized_assessment(demo_targets[0], "web")
    
    # 3. Configuration Test
    print(f"\n3️⃣ Configuration System:")
    try:
        from src.config import Config
        config = Config()
        print("✅ Configuration system loaded")
        print(f"   📊 Available settings: Multiple configuration options")
    except Exception as e:
        print(f"⚠️  Configuration test: {e}")
    
    print(f"\n🎉 Demo complete! The system is fully operational.")

def main():
    """Main application entry point"""
    
    parser = argparse.ArgumentParser(
        description="Automated Penetration Testing Orchestrator",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python autopentest_launcher.py --demo
  python autopentest_launcher.py --agentic --targets https://example.com 192.168.1.100
  python autopentest_launcher.py --analyze --targets target1 target2
  python autopentest_launcher.py --platform web --target https://example.com
        """
    )
    
    parser.add_argument('--demo', action='store_true', 
                       help='Run comprehensive system demonstration')
    parser.add_argument('--agentic', action='store_true',
                       help='Run full agentic AI assessment')
    parser.add_argument('--analyze', action='store_true',
                       help='Run AI analysis only (no execution)')
    parser.add_argument('--platform', choices=['network', 'web', 'mobile', 'wireless', 'cloud', 'iot'],
                       help='Specify platform for specialized assessment')
    parser.add_argument('--targets', nargs='+',
                       help='Target(s) for assessment')
    parser.add_argument('--target', 
                       help='Single target for platform-specific assessment')
    parser.add_argument('--version', action='version', version='AutoPentest v1.0.0')
    
    args = parser.parse_args()
    
    # Display banner
    banner()
    
    if args.demo:
        demo_mode()
        
    elif args.agentic and args.targets:
        asyncio.run(run_agentic_assessment(args.targets))
        
    elif args.analyze and args.targets:
        run_ai_analysis(args.targets)
        
    elif args.platform and args.target:
        run_specialized_assessment(args.target, args.platform)
        
    elif not any([args.demo, args.agentic, args.analyze, args.platform]):
        # Default: run demo
        print("🎯 No specific mode selected, running demonstration...")
        demo_mode()
        
    else:
        print("❌ Invalid argument combination. Use --help for usage information.")
        parser.print_help()

if __name__ == "__main__":
    main()
